{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to dev json to sql with spark using local json file. Then implement on ec2 instance for pipeining. \n",
    "import pyspark as ps\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (ps.sql.SparkSession\n",
    "         .builder\n",
    "         .master('local[4]')\n",
    "         .appName('lecture')\n",
    "         .getOrCreate()\n",
    "        )\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded test df (COVID only CO)\n",
    "df = spark.read.format('json').load(\"../zip_data/data/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contributors',\n",
       " 'coordinates',\n",
       " 'created_at',\n",
       " 'display_text_range',\n",
       " 'entities',\n",
       " 'extended_entities',\n",
       " 'extended_tweet',\n",
       " 'favorite_count',\n",
       " 'favorited',\n",
       " 'filter_level',\n",
       " 'geo',\n",
       " 'id',\n",
       " 'id_str',\n",
       " 'in_reply_to_screen_name',\n",
       " 'in_reply_to_status_id',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'is_quote_status',\n",
       " 'lang',\n",
       " 'limit',\n",
       " 'place',\n",
       " 'possibly_sensitive',\n",
       " 'quote_count',\n",
       " 'quoted_status',\n",
       " 'quoted_status_id',\n",
       " 'quoted_status_id_str',\n",
       " 'quoted_status_permalink',\n",
       " 'reply_count',\n",
       " 'retweet_count',\n",
       " 'retweeted',\n",
       " 'retweeted_status',\n",
       " 'source',\n",
       " 'text',\n",
       " 'timestamp_ms',\n",
       " 'truncated',\n",
       " 'user',\n",
       " 'withheld_in_countries']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsect colums that I want for 'tweets' table\n",
    "tweet_col_lst = ['id','user','lang','entities','place','created_at','text','source']\n",
    "tweet_col_df = df[tweet_col_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+----+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|                 id|                user|lang|            entities|place|          created_at|                text|              source|\n",
      "+-------------------+--------------------+----+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|1245439863907852289|[false, Mon Feb 2...|  en|[[],, [], [], [[1...| null|Wed Apr 01 19:56:...|RT @ChristinePolo...|<a href=\"http://t...|\n",
      "+-------------------+--------------------+----+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_col_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- user: struct (nullable = true)\n",
      " |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- default_profile: boolean (nullable = true)\n",
      " |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |-- description: string (nullable = true)\n",
      " |    |-- favourites_count: long (nullable = true)\n",
      " |    |-- follow_request_sent: string (nullable = true)\n",
      " |    |-- followers_count: long (nullable = true)\n",
      " |    |-- following: string (nullable = true)\n",
      " |    |-- friends_count: long (nullable = true)\n",
      " |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- is_translator: boolean (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- listed_count: long (nullable = true)\n",
      " |    |-- location: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- notifications: string (nullable = true)\n",
      " |    |-- profile_background_color: string (nullable = true)\n",
      " |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |-- profile_image_url: string (nullable = true)\n",
      " |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |-- profile_link_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |-- profile_text_color: string (nullable = true)\n",
      " |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |-- protected: boolean (nullable = true)\n",
      " |    |-- screen_name: string (nullable = true)\n",
      " |    |-- statuses_count: long (nullable = true)\n",
      " |    |-- time_zone: string (nullable = true)\n",
      " |    |-- translator_type: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- utc_offset: string (nullable = true)\n",
      " |    |-- verified: boolean (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- entities: struct (nullable = true)\n",
      " |    |-- hashtags: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |-- media: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- additional_media_info: struct (nullable = true)\n",
      " |    |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |    |-- embeddable: boolean (nullable = true)\n",
      " |    |    |    |    |-- monetizable: boolean (nullable = true)\n",
      " |    |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |-- source_user_id: long (nullable = true)\n",
      " |    |    |    |-- source_user_id_str: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- symbols: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |-- urls: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- screen_name: string (nullable = true)\n",
      " |-- place: struct (nullable = true)\n",
      " |    |-- bounding_box: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- country_code: string (nullable = true)\n",
      " |    |-- full_name: string (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- place_type: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_col_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5005"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_col_df.cache()\n",
    "tweet_col_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'state'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_col_df=tweet_col_df.withColumn('state',lit('co'))\n",
    "tweet_col_df=tweet_col_df.withColumn('search_term_key',lit(1))\n",
    "tweet_col_df['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_col_df.createOrReplaceTempView('tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`search_term`' given input columns: [tweets.created_at, tweets.entities, tweets.lang, tweets.id, tweets.search_term_key, tweets.user, tweets.text, tweets.source, tweets.place, tweets.state]; line 5 pos 8;\\n'Project [place#27.full_name AS geo_name#245, state#224, 'search_term]\\n+- Filter (isnotnull(place#27.full_name) && (lang#25 = en))\\n   +- SubqueryAlias `tweets`\\n      +- Project [id#17L, user#42, lang#25, entities#10, place#27, created_at#8, text#39, source#38, state#224, 1 AS search_term_key#234]\\n         +- Project [id#17L, user#42, lang#25, entities#10, place#27, created_at#8, text#39, source#38, co AS state#224]\\n            +- Project [id#17L, user#42, lang#25, entities#10, place#27, created_at#8, text#39, source#38]\\n               +- Relation[contributors#6,coordinates#7,created_at#8,display_text_range#9,entities#10,extended_entities#11,extended_tweet#12,favorite_count#13L,favorited#14,filter_level#15,geo#16,id#17L,id_str#18,in_reply_to_screen_name#19,in_reply_to_status_id#20L,in_reply_to_status_id_str#21,in_reply_to_user_id#22L,in_reply_to_user_id_str#23,is_quote_status#24,lang#25,limit#26,place#27,possibly_sensitive#28,quote_count#29L,... 14 more fields] json\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o24.sql.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`search_term`' given input columns: [tweets.created_at, tweets.entities, tweets.lang, tweets.id, tweets.search_term_key, tweets.user, tweets.text, tweets.source, tweets.place, tweets.state]; line 5 pos 8;\n'Project [place#27.full_name AS geo_name#245, state#224, 'search_term]\n+- Filter (isnotnull(place#27.full_name) && (lang#25 = en))\n   +- SubqueryAlias `tweets`\n      +- Project [id#17L, user#42, lang#25, entities#10, place#27, created_at#8, text#39, source#38, state#224, 1 AS search_term_key#234]\n         +- Project [id#17L, user#42, lang#25, entities#10, place#27, created_at#8, text#39, source#38, co AS state#224]\n            +- Project [id#17L, user#42, lang#25, entities#10, place#27, created_at#8, text#39, source#38]\n               +- Relation[contributors#6,coordinates#7,created_at#8,display_text_range#9,entities#10,extended_entities#11,extended_tweet#12,favorite_count#13L,favorited#14,filter_level#15,geo#16,id#17L,id_str#18,in_reply_to_screen_name#19,in_reply_to_status_id#20L,in_reply_to_status_id_str#21,in_reply_to_user_id#22L,in_reply_to_user_id_str#23,is_quote_status#24,lang#25,limit#26,place#27,possibly_sensitive#28,quote_count#29L,... 14 more fields] json\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:111)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:296)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1b252262c951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         (place.`full_name` IS NOT NULL AND\n\u001b[1;32m     10\u001b[0m         lang = 'en')\n\u001b[0;32m---> 11\u001b[0;31m     ''')\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`search_term`' given input columns: [tweets.created_at, tweets.entities, tweets.lang, tweets.id, tweets.search_term_key, tweets.user, tweets.text, tweets.source, tweets.place, tweets.state]; line 5 pos 8;\\n'Project [place#27.full_name AS geo_name#245, state#224, 'search_term]\\n+- Filter (isnotnull(place#27.full_name) && (lang#25 = en))\\n   +- SubqueryAlias `tweets`\\n      +- Project [id#17L, user#42, lang#25, entities#10, place#27, created_at#8, text#39, source#38, state#224, 1 AS search_term_key#234]\\n         +- Project [id#17L, user#42, lang#25, entities#10, place#27, created_at#8, text#39, source#38, co AS state#224]\\n            +- Project [id#17L, user#42, lang#25, entities#10, place#27, created_at#8, text#39, source#38]\\n               +- Relation[contributors#6,coordinates#7,created_at#8,display_text_range#9,entities#10,extended_entities#11,extended_tweet#12,favorite_count#13L,favorited#14,filter_level#15,geo#16,id#17L,id_str#18,in_reply_to_screen_name#19,in_reply_to_status_id#20L,in_reply_to_status_id_str#21,in_reply_to_user_id#22L,in_reply_to_user_id_str#23,is_quote_status#24,lang#25,limit#26,place#27,possibly_sensitive#28,quote_count#29L,... 14 more fields] json\\n\""
     ]
    }
   ],
   "source": [
    "\n",
    "place = spark.sql('''\n",
    "    SELECT\n",
    "        place.`full_name` AS geo_name,\n",
    "        state,\n",
    "        search_term\n",
    "    FROM\n",
    "        tweets\n",
    "    WHERE\n",
    "        (place.`full_name` IS NOT NULL AND\n",
    "        lang = 'en')\n",
    "    ''')\n",
    "print(type(place))\n",
    "place.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform SQL queries to make the tables I want, first tweets table\n",
    "\n",
    "temp = tweet_col_df.createOrReplaceTempView('tweets')\n",
    "\n",
    "tweet_tbl = spark.sql('''\n",
    "    SELECT \n",
    "        id AS tweet_id,\n",
    "        state,\n",
    "        search_term_key,\n",
    "        user.`id` AS user_id,\n",
    "        created_at AS time_created,\n",
    "        text AS tweet_text,\n",
    "        source,\n",
    "        place.`full_name` AS geo_name,\n",
    "        place.`id` AS geo_id,\n",
    "        place.`bounding_box`.`coordinates`[0][0][1] AS geo_coords_SW_lat,\n",
    "        place.`bounding_box`.`coordinates`[0][0][0] AS geo_coords_SW_long,\n",
    "        place.`bounding_box`.`coordinates`[0][2][1] AS geo_coords_NE_lat,\n",
    "        place.`bounding_box`.`coordinates`[0][2][0] AS geo_coords_NE_long,\n",
    "        entities.`hashtags`[0].`text` AS hash_tag_1,\n",
    "        entities.`hashtags`[1].`text` AS hash_tag_2,\n",
    "        entities.`hashtags`[2].`text` AS hash_tag_3,\n",
    "        entities.`hashtags`[3].`text` AS hash_tag_4,\n",
    "        entities.`hashtags`[4].`text` AS hash_tags_5,\n",
    "        entities.`user_mentions`[0].`screen_name` AS user_mentions_1,\n",
    "        entities.`user_mentions`[1].`screen_name` AS user_mentions_2,\n",
    "        entities.`user_mentions`[2].`screen_name` AS user_mentions_3,\n",
    "        entities.`user_mentions`[3].`screen_name` AS user_mentions_4,\n",
    "        entities.`user_mentions`[4].`screen_name` AS user_mentions_5,\n",
    "        user.`created_at` AS user_date_created,\n",
    "        user.`location` AS location,\n",
    "        user.`description` AS description\n",
    "    FROM tweets\n",
    "    WHERE\n",
    "        lang = 'en'\n",
    "    ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_id: long (nullable = true)\n",
      " |-- state: string (nullable = false)\n",
      " |-- search_term_key: integer (nullable = false)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- time_created: string (nullable = true)\n",
      " |-- tweet_text: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- geo_name: string (nullable = true)\n",
      " |-- geo_id: string (nullable = true)\n",
      " |-- geo_coords_SW_lat: double (nullable = true)\n",
      " |-- geo_coords_SW_long: double (nullable = true)\n",
      " |-- geo_coords_NE_lat: double (nullable = true)\n",
      " |-- geo_coords_NE_long: double (nullable = true)\n",
      " |-- hash_tag_1: string (nullable = true)\n",
      " |-- hash_tag_2: string (nullable = true)\n",
      " |-- hash_tag_3: string (nullable = true)\n",
      " |-- hash_tag_4: string (nullable = true)\n",
      " |-- hash_tags_5: string (nullable = true)\n",
      " |-- user_mentions_1: string (nullable = true)\n",
      " |-- user_mentions_2: string (nullable = true)\n",
      " |-- user_mentions_3: string (nullable = true)\n",
      " |-- user_mentions_4: string (nullable = true)\n",
      " |-- user_mentions_5: string (nullable = true)\n",
      " |-- user_date_created: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_schema = tweet_tbl.schema\n",
    "tweet_tbl.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tweets = tweet_tbl.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2767 entries, 0 to 2766\n",
      "Data columns (total 26 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   tweet_id            2767 non-null   int64  \n",
      " 1   state               2767 non-null   object \n",
      " 2   search_term_key     2767 non-null   int32  \n",
      " 3   user_id             2767 non-null   int64  \n",
      " 4   time_created        2767 non-null   object \n",
      " 5   tweet_text          2767 non-null   object \n",
      " 6   source              2767 non-null   object \n",
      " 7   geo_name            69 non-null     object \n",
      " 8   geo_id              69 non-null     object \n",
      " 9   geo_coords_SW_lat   69 non-null     float64\n",
      " 10  geo_coords_SW_long  69 non-null     float64\n",
      " 11  geo_coords_NE_lat   69 non-null     float64\n",
      " 12  geo_coords_NE_long  69 non-null     float64\n",
      " 13  hash_tag_1          1564 non-null   object \n",
      " 14  hash_tag_2          579 non-null    object \n",
      " 15  hash_tag_3          219 non-null    object \n",
      " 16  hash_tag_4          107 non-null    object \n",
      " 17  hash_tags_5         56 non-null     object \n",
      " 18  user_mentions_1     2343 non-null   object \n",
      " 19  user_mentions_2     495 non-null    object \n",
      " 20  user_mentions_3     146 non-null    object \n",
      " 21  user_mentions_4     61 non-null     object \n",
      " 22  user_mentions_5     31 non-null     object \n",
      " 23  user_date_created   2767 non-null   object \n",
      " 24  location            1984 non-null   object \n",
      " 25  description         2342 non-null   object \n",
      "dtypes: float64(4), int32(1), int64(2), object(19)\n",
      "memory usage: 551.4+ KB\n"
     ]
    }
   ],
   "source": [
    "pd_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wed Apr 01 19:56:17 +0000 2020'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_date = pd_tweets['time_created']\n",
    "tweet_date[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-04-01 19:56:17+0000', tz='UTC')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(tweet_date[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_date_formated = tweet_date.map(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       co\n",
       "1       co\n",
       "2       co\n",
       "3       co\n",
       "4       co\n",
       "        ..\n",
       "2762    co\n",
       "2763    co\n",
       "2764    co\n",
       "2765    co\n",
       "2766    co\n",
       "Name: state, Length: 2767, dtype: string"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_tweets['state'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2767 entries, 0 to 2766\n",
      "Data columns (total 26 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   tweet_id            2767 non-null   int64  \n",
      " 1   state               2767 non-null   object \n",
      " 2   search_term_key     2767 non-null   int32  \n",
      " 3   user_id             2767 non-null   int64  \n",
      " 4   time_created        2767 non-null   object \n",
      " 5   tweet_text          2767 non-null   object \n",
      " 6   source              2767 non-null   object \n",
      " 7   geo_name            69 non-null     object \n",
      " 8   geo_id              69 non-null     object \n",
      " 9   geo_coords_SW_lat   69 non-null     float64\n",
      " 10  geo_coords_SW_long  69 non-null     float64\n",
      " 11  geo_coords_NE_lat   69 non-null     float64\n",
      " 12  geo_coords_NE_long  69 non-null     float64\n",
      " 13  hash_tag_1          1564 non-null   object \n",
      " 14  hash_tag_2          579 non-null    object \n",
      " 15  hash_tag_3          219 non-null    object \n",
      " 16  hash_tag_4          107 non-null    object \n",
      " 17  hash_tags_5         56 non-null     object \n",
      " 18  user_mentions_1     2343 non-null   object \n",
      " 19  user_mentions_2     495 non-null    object \n",
      " 20  user_mentions_3     146 non-null    object \n",
      " 21  user_mentions_4     61 non-null     object \n",
      " 22  user_mentions_5     31 non-null     object \n",
      " 23  user_date_created   2767 non-null   object \n",
      " 24  location            1984 non-null   object \n",
      " 25  description         2342 non-null   object \n",
      "dtypes: float64(4), int32(1), int64(2), object(19)\n",
      "memory usage: 551.4+ KB\n"
     ]
    }
   ],
   "source": [
    "pd_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'geo_coords'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'geo_coords'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-05f357cec725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geo_coords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geo_coords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'geo_coords'"
     ]
    }
   ],
   "source": [
    "pd_tweets['geo_coords'][pd_tweets['geo_coords'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'geo_coords'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'geo_coords'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f56184ebdfab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geo_coords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geo_coords_two'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'geo_coords'"
     ]
    }
   ],
   "source": [
    "print(pd_tweets['geo_coords'][34], pd_tweets['geo_coords_two'][34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Los Angeles, CA'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_tweets['geo_name'][34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>state</th>\n",
       "      <th>search_term_key</th>\n",
       "      <th>user_id</th>\n",
       "      <th>time_created</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>source</th>\n",
       "      <th>geo_name</th>\n",
       "      <th>geo_id</th>\n",
       "      <th>geo_coords_SW_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>hash_tag_4</th>\n",
       "      <th>hash_tags_5</th>\n",
       "      <th>user_mentions_1</th>\n",
       "      <th>user_mentions_2</th>\n",
       "      <th>user_mentions_3</th>\n",
       "      <th>user_mentions_4</th>\n",
       "      <th>user_mentions_5</th>\n",
       "      <th>user_date_created</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1245439863907852289</td>\n",
       "      <td>co</td>\n",
       "      <td>1</td>\n",
       "      <td>968218684702560261</td>\n",
       "      <td>Wed Apr 01 19:56:17 +0000 2020</td>\n",
       "      <td>RT @ChristinePolon1: I just called this hospit...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ChristinePolon1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Feb 26 20:18:17 +0000 2018</td>\n",
       "      <td>Michigan, USA</td>\n",
       "      <td>#Truth #MAGA #KAG #Q #QAnon #GreatAwakening  #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245439864130191362</td>\n",
       "      <td>co</td>\n",
       "      <td>1</td>\n",
       "      <td>41109216</td>\n",
       "      <td>Wed Apr 01 19:56:17 +0000 2020</td>\n",
       "      <td>RT @socialistworker: Hungarys government effe...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>socialistworker</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Tue May 19 12:56:52 +0000 2009</td>\n",
       "      <td>London UK</td>\n",
       "      <td>I AM A CITIZEN OF THE WORLD \\nI am a Globalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245439864197218304</td>\n",
       "      <td>co</td>\n",
       "      <td>1</td>\n",
       "      <td>550338885</td>\n",
       "      <td>Wed Apr 01 19:56:17 +0000 2020</td>\n",
       "      <td>RT @JustinBrannan: Dear @Amazon,\\n\\nWith peopl...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>JustinBrannan</td>\n",
       "      <td>amazon</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Tue Apr 10 16:42:11 +0000 2012</td>\n",
       "      <td>None</td>\n",
       "      <td>I dont know her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245439864331436032</td>\n",
       "      <td>co</td>\n",
       "      <td>1</td>\n",
       "      <td>1149028897247416320</td>\n",
       "      <td>Wed Apr 01 19:56:17 +0000 2020</td>\n",
       "      <td>UV DISINFECTION - UV LIGHT AND COVID-19 (CORON...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Wed Jul 10 18:53:31 +0000 2019</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>BSN RN OR/CVOR/IR/GI. Jesus is #1. DM, chats...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245439864943906817</td>\n",
       "      <td>co</td>\n",
       "      <td>1</td>\n",
       "      <td>1146317592556122112</td>\n",
       "      <td>Wed Apr 01 19:56:17 +0000 2020</td>\n",
       "      <td>RT @KemiOlunloyo: #BREAKING  I am calling for ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>KemiOlunloyo</td>\n",
       "      <td>HE_HopeUzodimma</td>\n",
       "      <td>NCDCgov</td>\n",
       "      <td>Chikwe_I</td>\n",
       "      <td>None</td>\n",
       "      <td>Wed Jul 03 07:19:46 +0000 2019</td>\n",
       "      <td>None</td>\n",
       "      <td>A bio can't explain ME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id state  search_term_key              user_id  \\\n",
       "0  1245439863907852289    co                1   968218684702560261   \n",
       "1  1245439864130191362    co                1             41109216   \n",
       "2  1245439864197218304    co                1            550338885   \n",
       "3  1245439864331436032    co                1  1149028897247416320   \n",
       "4  1245439864943906817    co                1  1146317592556122112   \n",
       "\n",
       "                     time_created  \\\n",
       "0  Wed Apr 01 19:56:17 +0000 2020   \n",
       "1  Wed Apr 01 19:56:17 +0000 2020   \n",
       "2  Wed Apr 01 19:56:17 +0000 2020   \n",
       "3  Wed Apr 01 19:56:17 +0000 2020   \n",
       "4  Wed Apr 01 19:56:17 +0000 2020   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  RT @ChristinePolon1: I just called this hospit...   \n",
       "1  RT @socialistworker: Hungarys government effe...   \n",
       "2  RT @JustinBrannan: Dear @Amazon,\\n\\nWith peopl...   \n",
       "3  UV DISINFECTION - UV LIGHT AND COVID-19 (CORON...   \n",
       "4  RT @KemiOlunloyo: #BREAKING  I am calling for ...   \n",
       "\n",
       "                                              source geo_name geo_id  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...     None   None   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...     None   None   \n",
       "2  <a href=\"https://mobile.twitter.com\" rel=\"nofo...     None   None   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...     None   None   \n",
       "4  <a href=\"http://twitter.com/download/android\" ...     None   None   \n",
       "\n",
       "   geo_coords_SW_lat  ...  hash_tag_4  hash_tags_5  user_mentions_1  \\\n",
       "0                NaN  ...        None         None  ChristinePolon1   \n",
       "1                NaN  ...        None         None  socialistworker   \n",
       "2                NaN  ...        None         None    JustinBrannan   \n",
       "3                NaN  ...        None         None             None   \n",
       "4                NaN  ...        None         None     KemiOlunloyo   \n",
       "\n",
       "   user_mentions_2 user_mentions_3 user_mentions_4 user_mentions_5  \\\n",
       "0             None            None            None            None   \n",
       "1             None            None            None            None   \n",
       "2           amazon            None            None            None   \n",
       "3             None            None            None            None   \n",
       "4  HE_HopeUzodimma         NCDCgov        Chikwe_I            None   \n",
       "\n",
       "                user_date_created       location  \\\n",
       "0  Mon Feb 26 20:18:17 +0000 2018  Michigan, USA   \n",
       "1  Tue May 19 12:56:52 +0000 2009      London UK   \n",
       "2  Tue Apr 10 16:42:11 +0000 2012           None   \n",
       "3  Wed Jul 10 18:53:31 +0000 2019     Texas, USA   \n",
       "4  Wed Jul 03 07:19:46 +0000 2019           None   \n",
       "\n",
       "                                         description  \n",
       "0  #Truth #MAGA #KAG #Q #QAnon #GreatAwakening  #...  \n",
       "1  I AM A CITIZEN OF THE WORLD \\nI am a Globalis...  \n",
       "2                                  I dont know her.  \n",
       "3  BSN RN OR/CVOR/IR/GI. Jesus is #1. DM, chats...  \n",
       "4                             A bio can't explain ME  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = pd_tweets[['tweet_text', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tweet_text['pre_clean_length_text'] = [len(t) for t in tweet_text['tweet_text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>description</th>\n",
       "      <th>pre_clean_length_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ChristinePolon1: I just called this hospit...</td>\n",
       "      <td>#Truth #MAGA #KAG #Q #QAnon #GreatAwakening  #...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @socialistworker: Hungarys government effe...</td>\n",
       "      <td>I AM A CITIZEN OF THE WORLD \\nI am a Globalis...</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @JustinBrannan: Dear @Amazon,\\n\\nWith peopl...</td>\n",
       "      <td>I dont know her.</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UV DISINFECTION - UV LIGHT AND COVID-19 (CORON...</td>\n",
       "      <td>BSN RN OR/CVOR/IR/GI. Jesus is #1. DM, chats...</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @KemiOlunloyo: #BREAKING  I am calling for ...</td>\n",
       "      <td>A bio can't explain ME</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  RT @ChristinePolon1: I just called this hospit...   \n",
       "1  RT @socialistworker: Hungarys government effe...   \n",
       "2  RT @JustinBrannan: Dear @Amazon,\\n\\nWith peopl...   \n",
       "3  UV DISINFECTION - UV LIGHT AND COVID-19 (CORON...   \n",
       "4  RT @KemiOlunloyo: #BREAKING  I am calling for ...   \n",
       "\n",
       "                                         description  pre_clean_length_text  \n",
       "0  #Truth #MAGA #KAG #Q #QAnon #GreatAwakening  #...                    140  \n",
       "1  I AM A CITIZEN OF THE WORLD \\nI am a Globalis...                    139  \n",
       "2                                  I dont know her.                    140  \n",
       "3  BSN RN OR/CVOR/IR/GI. Jesus is #1. DM, chats...                    129  \n",
       "4                             A bio can't explain ME                    140  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>description</th>\n",
       "      <th>pre_clean_length_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RT @RepJimBanks: Heartbreaking story about Ai ...</td>\n",
       "      <td>None</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RT @Davidshal20: @pulte Due to #COVID19 known ...</td>\n",
       "      <td>Account parodia</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RT @codepink: The people of #Iran are suffocat...</td>\n",
       "      <td>writer, teacher, mom, cultural and political a...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>RT @jazzzy_10: Due to #COVID19 aka #Coronaviru...</td>\n",
       "      <td>you have to be odd to be number one ~Dr. seuss</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>RT @PIB_India: Actor @Suriya_offl appeals peop...</td>\n",
       "      <td>@samsung SEC</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>RT @PHLJazzProject: Just as I was putting toge...</td>\n",
       "      <td>Philadelphias most reliable and ambitious pr...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>RT @TrinityResists: Trump &amp;amp; his regime out...</td>\n",
       "      <td>Progressive, Mom, Middle Class, Passionate Abo...</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>RT @USAIDEthiopia: To support #COVID19 respons...</td>\n",
       "      <td>Lecturer @ AAU, CHS, SOM\\n\\nInternational Medi...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>RT @MichaelMaidment: Hey #Ottawa. When you dec...</td>\n",
       "      <td>Director Comms &amp; Gov. Relations @UNHCRCanada, ...</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>RT @MalcolmNance: OMG this is a disasterous jo...</td>\n",
       "      <td>The Prince of Prints has been in the imaging b...</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "15    RT @RepJimBanks: Heartbreaking story about Ai ...   \n",
       "20    RT @Davidshal20: @pulte Due to #COVID19 known ...   \n",
       "29    RT @codepink: The people of #Iran are suffocat...   \n",
       "51    RT @jazzzy_10: Due to #COVID19 aka #Coronaviru...   \n",
       "59    RT @PIB_India: Actor @Suriya_offl appeals peop...   \n",
       "...                                                 ...   \n",
       "2706  RT @PHLJazzProject: Just as I was putting toge...   \n",
       "2707  RT @TrinityResists: Trump &amp; his regime out...   \n",
       "2713  RT @USAIDEthiopia: To support #COVID19 respons...   \n",
       "2718  RT @MichaelMaidment: Hey #Ottawa. When you dec...   \n",
       "2734  RT @MalcolmNance: OMG this is a disasterous jo...   \n",
       "\n",
       "                                            description  pre_clean_length_text  \n",
       "15                                                 None                    144  \n",
       "20                                      Account parodia                    148  \n",
       "29    writer, teacher, mom, cultural and political a...                    144  \n",
       "51       you have to be odd to be number one ~Dr. seuss                    144  \n",
       "59                                         @samsung SEC                    144  \n",
       "...                                                 ...                    ...  \n",
       "2706  Philadelphias most reliable and ambitious pr...                    144  \n",
       "2707  Progressive, Mom, Middle Class, Passionate Abo...                    152  \n",
       "2713  Lecturer @ AAU, CHS, SOM\\n\\nInternational Medi...                    144  \n",
       "2718  Director Comms & Gov. Relations @UNHCRCanada, ...                    143  \n",
       "2734  The Prince of Prints has been in the imaging b...                    143  \n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text[tweet_text.pre_clean_length_text > 140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @RepJimBanks: Heartbreaking story about Ai Fen, a Chinese doc who raised alarm about #COVID19 in early Dec &amp; is now missing.\\n\\n@StateDept'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text.tweet_text[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       RT @ChristinePolon1: I just called this hospit...\n",
       "1       RT @socialistworker: Hungarys government effe...\n",
       "2       RT @JustinBrannan: Dear @Amazon,\\n\\nWith peopl...\n",
       "3       UV DISINFECTION - UV LIGHT AND COVID-19 (CORON...\n",
       "4       RT @KemiOlunloyo: #BREAKING  I am calling for ...\n",
       "                              ...                        \n",
       "2762    RT @AltafHussain_90: Dear President @realDonal...\n",
       "2763    RT @DavidTRobins: @FoxNews spews lies. Hold th...\n",
       "2764                     What is the first stimulus bill?\n",
       "2765    @khamenei_ir \\n@HassanRouhani \\nWhat prosperit...\n",
       "2766    RT @natureheals616: @the_resistor @washingtonp...\n",
       "Name: tweet_text, Length: 2767, dtype: object"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = tweet_text.tweet_text.str.contains(r\"\\w\", na=False)\n",
    "tweet_text.tweet_text.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UV DISINFECTION - UV LIGHT AND COVID-19 (CORONAVIRUS)  UV Disinfection #SaveLives #COVID19 #Covid_19USA https://t.co/CWspARIsGZ'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text.tweet_text[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = re.sub(r'http\\S+','',tweet_text.tweet_text[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negation_dic.keys()) + r')\\b')\n",
    "neg_pattern\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_abbs = { 'lol': 'laughing out loud', 'bfn': 'bye for now', 'cuz': 'because',\n",
    "        'afk': 'away from keyboard', 'nvm': 'never mind', 'iirc': 'if i recall correctly',\n",
    "        'ttyl': 'talk to you later', 'imho': 'in my honest opinion', 'brb': 'be right back' }\n",
    "\n",
    "grammar_abbs = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "            \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "            \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "            \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "            \"mustn't\":\"must not\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt @repjimbanks: heartbreaking story about ai fen, a chinese doc who raised alarm about #covid19 in early dec &amp; is now missing. @statedept\n",
      "rt  repjimbanks  heartbreaking story about ai fen  a chinese doc who raised alarm about  covid19 in early dec  is now missing   statedept\n",
      "['']\n",
      "[b'\\xe2\\x80\\xa6']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "test = [r'http\\S+', r'&amp; ', r\"[@#]\", r\"[!$%()*+,-./:;<=>?\\^_`{|}~]\"]\n",
    "# print(test)    r'[^a-zA-Z]'\n",
    "t1 = tweet_text.tweet_text[15].lower()\n",
    "t2 = ' '.join([text_abbs.get(word,word) for word in t1.split()])\n",
    "t2 = ' '.join([grammar_abbs.get(word,word) for word in t1.split()])\n",
    "print(t2)\n",
    "\n",
    "test2 = '|'.join([elem for elem in test])\n",
    "\n",
    "t3 = re.sub(test2,' ',t2)\n",
    "print(t3)\n",
    "\n",
    "t4 = re.sub(r'\\w','',t3).split()\n",
    "print(t4)\n",
    "# t5 = t4.split()\n",
    "t6=[word.decode('utf-8') for word in t5]\n",
    "print(t5)\n",
    "print(t6)\n",
    "# t5 = ' '.join([elem for elem in t4.split()])\n",
    "# print(t5)\n",
    "\n",
    "# t5 = ' '.join([elem for elem in t4.split() if elem not in stopwords])\n",
    "# print(t5)\n",
    "# # .apply(lambda x: re.sub(r'\\w','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @RepJimBanks: Heartbreaking story about Ai Fen, a Chinese doc who raised alarm about #COVID19 in early Dec &amp; is now missing.\n",
      "\n",
      "@StateDept\n",
      "RT @RepJimBanks: Heartbreaking story about Ai Fen, a Chinese doc who raised alarm about #COVID19 in early Dec is now missing.\n",
      "\n",
      "@StateDept\n",
      "RT RepJimBanks: Heartbreaking story about Ai Fen, a Chinese doc who raised alarm about COVID19 in early Dec is now missing.\n",
      "\n",
      "StateDept\n",
      "rt repjimbanks: heartbreaking story about ai fen, a chinese doc who raised alarm about covid19 in early dec is now missing.\n",
      "\n",
      "statedept\n",
      "rt repjimbanks heartbreaking story about ai fen a chinese doc who raised alarm about covid19 in early dec is now missing\n",
      "\n",
      "statedept\n",
      "['rt', '', 'amandaalvaro', 'this', 'is', 'such', 'a', 'bad', 'look', 'for', 'the', 'conservative', 'party', 'i', \"can't\", 'think', 'of', 'a', 'worse', 'time', 'to', 'put', 'partisan', 'interests', 'ahead', 'of', 'publ']\n",
      "rt repjimbanks heartbreaking story about ai fen a chinese doc who raised alarm about covid19 in early dec is now missing statedept\n",
      "rt repjimbanks heartbreaking story about ai fen a chinese doc who raised alarm about covid   in early dec is now missing statedept \n",
      "['rt', 'repjimbanks', 'heartbreaking', 'story', 'about', 'ai', 'fen', 'a', 'chinese', 'doc', 'who', 'raised', 'alarm', 'about', 'covid', 'in', 'early', 'dec', 'is', 'now', 'missing', 'statedept']\n",
      "rt repjimbanks heartbreaking story about ai fen a chinese doc who raised alarm about covid in early dec is now missing statedept\n"
     ]
    }
   ],
   "source": [
    "t1 = re.sub(r'http\\S+','',tweet_text.tweet_text[15])\n",
    "print(t1)\n",
    "t2 = re.sub(r'&amp; ','',t1)\n",
    "print(t2)\n",
    "t3 = re.sub(r\"[@#]\",'',t2)\n",
    "print(t3)\n",
    "t4 =t3.lower()\n",
    "print(t4)\n",
    "t5 =re.sub(r\"[!$%()*+,-./:;<=>?\\^_`{|}~]\",'',t4)\n",
    "print(t5)\n",
    "print(split)\n",
    "\n",
    "t5 = ' '.join([text_abbs.get(word,word) for word in t5.split()])\n",
    "t5 = ' '.join([grammar_abbs.get(word,word) for word in t5.split()])\n",
    "print(t5)\n",
    "t6 = re.sub(r'[^a-zA-Z]',' ',t5)\n",
    "print(t6)\n",
    "t7 = t6.split()\n",
    "print(t7)\n",
    "t7 = ' '.join([word for word in t6.split()])\n",
    "print(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @ReporterClaudia: Pasadena has reported its first two deaths so that brings the county's total to 93. Total new #COVID19-related deaths\n",
      "RT @ReporterClaudia: Pasadena has reported its first two deaths so that brings the county's total to 93. Total new #COVID19-related deaths\n",
      "RT  ReporterClaudia: Pasadena has reported its first two deaths so that brings the county's total to 93. Total new  COVID19-related deaths\n",
      "rt  reporterclaudia: pasadena has reported its first two deaths so that brings the county's total to 93. total new  covid19-related deaths\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "unterminated character set at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-bfaf4dd2fbdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mt5\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mt6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^a-zA-Z]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, pattern)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0;32m--> 420\u001b[0;31m                            not nested and not items))\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    524\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                     raise source.error(\"unterminated character set\",\n\u001b[0;32m--> 526\u001b[0;31m                                        source.tell() - here)\n\u001b[0m\u001b[1;32m    527\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"]\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: unterminated character set at position 0"
     ]
    }
   ],
   "source": [
    "t1 = re.sub(r'http\\S+','',tweet_text.tweet_text[2005])\n",
    "print(t1)\n",
    "t2 = re.sub(r'&amp; ','',t1)\n",
    "print(t2)\n",
    "t3 = re.sub(r\"[@#]\",' ',t2)\n",
    "print(t3)\n",
    "t4 =t3.lower()\n",
    "print(t4)\n",
    "print(punctuation)\n",
    "t5 =re.sub(r'[]',' ',t4)\n",
    "print(t5)\n",
    "t6 = re.sub(r'[^a-zA-Z]',' ',t5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tweet_text['emojis'] = tweet_text['tweet_text'].apply(lambda x: re.sub(r'\\w','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' @:       ...  \\u200d  # ://./'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text.emojis[2004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT : Heartbreaking story about Ai Fen, a Chinese doc who raised alarm about #COVID19 in early Dec &amp; is now missing.\n",
      "\n",
      "\n",
      "RT : Heartbreaking story about Ai Fen, a Chinese doc who raised alarm about #COVID19 in early Dec is now missing.\n",
      "\n",
      "\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "t1 = re.sub(r'@[A-Za-z0-9]+','',tweet_text.tweet_text[3])\n",
    "print(t1)\n",
    "t2 = re.sub(r'&amp; ','',t1)\n",
    "print(t2)\n",
    "print(type(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@[A-Za-z0-9]+|https?://[A-Za-z0-9./]+'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "combined_pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RT @JustinBrannan: Dear @Amazon,\\n\\nWith people forced to stay safe inside from #COVID19, \\nyou are making more $$ than ever before. \\n\\nNow's n\""
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_lst = tweet_text.tweet_text.tolist()\n",
    "tweet_lst[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT JustinBrannan Dear Amazon\\n\\nWith people forced to stay safe inside from COVID19 \\nyou are making more  than ever before \\n\\nNows n'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([c for c in tweet_lst[2] if c not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_strings = tweet_text['tweet_text'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358230"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import lxml\n",
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "#     soup = BeautifulSoup(text, 'lxml')\n",
    "#     souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', text)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @codepink: The people of #Iran are suffocating &amp; the people of #Venezuela are suffering as the US continues to impose brutal sanctions o\n",
      "rt the people of iran are suffocating amp the people of venezuela are suffering as the us continues to impose brutal sanctions o\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "test = tweet_cleaner(tweet_lst[29])\n",
    "print(tweet_lst[29])\n",
    "print(test)\n",
    "print(type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "from sklearn.feature_extraction import stop_words\n",
    "stopwords = stop_words.ENGLISH_STOP_WORDS\n",
    "\n",
    "def lowercase_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_punctuation(text, punctuation=punctuation):\n",
    "    return ''.join([c for c in text if c not in punctuation])\n",
    "\n",
    "def remove_newline(text):\n",
    "    return text.replace('\\n', '')\n",
    "\n",
    "def split_text_into_words(text):\n",
    "    return text.split(' ')\n",
    "\n",
    "def remove_stopwords(word_lst, stopwords_set):\n",
    "    return [word for word in word_lst if word not in stopwords_set]\n",
    "\n",
    "def replace_names(word_lst, name_set, replacement_val):\n",
    "    word_lst_with_replacement = [] \n",
    "    for word in word_lst:\n",
    "        if word in name_set:\n",
    "            val = replacement_val\n",
    "        else:\n",
    "            val = word\n",
    "        word_lst_with_replacement.append(val)\n",
    "    return word_lst_with_replacement\n",
    "\n",
    "def create_cleaned_textline_from_words(words):\n",
    "    text = ' '.join([word for word in words])\n",
    "    return text\n",
    "\n",
    "def line_cleaning_pipeline(text, stopwords_set, name_set, replace_val):\n",
    "    text_lc = lowercase_text(text)\n",
    "    text_np = remove_punctuation(text_lc)\n",
    "    text_nnl = remove_newline(text_np)\n",
    "    words = split_text_into_words(text_nnl)\n",
    "    words_nsw = remove_stopwords(words, stopwords_set)\n",
    "    words_cleaned = replace_names(words_nsw, name_set, replace_val) \n",
    "    line_of_text_cleaned = create_cleaned_textline_from_words(words_cleaned)\n",
    "    return line_of_text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'do',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fifty',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'was',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
